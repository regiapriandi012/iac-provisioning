pipeline {
    agent any
    
    parameters {
        choice(
            name: 'cluster_preset',
            choices: ['custom', 'small-single-master', 'medium-single-master', 'ha-3-masters'],
            description: 'Choose a preset or select custom to use vm_csv_content'
        )
        choice(
            name: 'vm_template',
            choices: ['t-debian12-86', 't-centos9-86'],
            description: 'VM template to use for all nodes'
        )
        string(
            name: 'proxmox_node',
            defaultValue: 'thinkcentre',
            description: 'Proxmox node where VMs will be created'
        )
        text(
            name: 'vm_csv_content',
            defaultValue: '''vmid,vm_name,template,node,ip,cores,memory,disk_size
0,kube-master,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,2,4096,32G
0,kube-worker01,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,2,4096,32G
0,kube-worker02,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,2,4096,32G''',
            description: 'VM specifications in CSV format (used when cluster_preset is "custom"). TEMPLATE_PLACEHOLDER and NODE_PLACEHOLDER will be replaced with selected values.'
        )
        booleanParam(
            name: 'run_ansible',
            defaultValue: true,
            description: 'Run Ansible after Terraform apply'
        )
        booleanParam(
            name: 'skip_verification',
            defaultValue: false,
            description: 'Skip Kubernetes cluster verification steps'
        )
    }

    environment {
        TERRAFORM_DIR = 'terraform'
        ANSIBLE_DIR = 'ansible'
        ANSIBLE_CONFIG = "${ANSIBLE_DIR}/ansible.cfg"
        INVENTORY_FILE = 'inventory/k8s-inventory.json'
        INVENTORY_SCRIPT = 'inventory.py'
    }

    stages {
        stage('Checkout') {
            steps {
                git branch: 'main', 
                    credentialsId: 'gitlab-credential', 
                    url: 'https://gitlab.labngoprek.my.id/root/iac-provision'
            }
        }
        
        stage('Generate VM Configuration') {
            steps {
                dir("${TERRAFORM_DIR}") {
                    script {
                        // Generate CSV based on preset or custom input
                        def csvContent = ""
                        
                        if (params.cluster_preset == 'custom') {
                            // Use custom CSV content
                            csvContent = params.vm_csv_content
                        } else {
                            // Use preset configurations with placeholders
                            def presetConfigs = [
                                'small-single-master': '''vmid,vm_name,template,node,ip,cores,memory,disk_size
0,kube-master,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,2,4096,50G
0,kube-worker01,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,2,4096,50G
0,kube-worker02,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,2,4096,50G''',
                                
                                'medium-single-master': '''vmid,vm_name,template,node,ip,cores,memory,disk_size
0,kube-master,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,100G
0,kube-worker01,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,100G
0,kube-worker02,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,100G
0,kube-worker03,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,100G''',
                                
                                'ha-3-masters': '''vmid,vm_name,template,node,ip,cores,memory,disk_size
0,kube-master01,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,50G
0,kube-master02,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,50G
0,kube-master03,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,50G
0,kube-worker01,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,100G
0,kube-worker02,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,100G
0,kube-worker03,TEMPLATE_PLACEHOLDER,NODE_PLACEHOLDER,0,4,8192,100G'''
                            ]
                            
                            csvContent = presetConfigs[params.cluster_preset]
                        }
                        
                        // Replace placeholders with actual values
                        csvContent = csvContent.replaceAll('TEMPLATE_PLACEHOLDER', params.vm_template)
                        csvContent = csvContent.replaceAll('NODE_PLACEHOLDER', params.proxmox_node)
                        
                        // Write final CSV to file
                        writeFile file: "vms.csv", text: csvContent
                            
                        sh """
                            echo "=========================================="
                            echo "Configuration:"
                            echo "- Preset/Mode: ${params.cluster_preset}"
                            echo "- Template: ${params.vm_template}"
                            echo "- Proxmox Node: ${params.proxmox_node}"
                            echo "=========================================="
                        """
                        
                        sh '''
                            echo "Generated vms.csv:"
                            cat vms.csv
                            echo ""
                            
                            # Debug: Show header and check format
                            echo "CSV Header:"
                            head -1 vms.csv | cat -A
                            echo ""
                            
                            # Validate CSV format (trim whitespace)
                            HEADER=$(head -1 vms.csv | tr -d '\\r' | tr -d ' ')
                            EXPECTED="vmid,vm_name,template,node,ip,cores,memory,disk_size"
                            
                            if [ "$HEADER" != "$EXPECTED" ]; then
                                echo "ERROR: Invalid CSV header format!"
                                echo "Expected: $EXPECTED"
                                echo "Got:      $HEADER"
                                exit 1
                            fi
                            
                            # Count VMs
                            VM_COUNT=$(tail -n +2 vms.csv | wc -l)
                            MASTER_COUNT=$(grep -i master vms.csv | wc -l)
                            WORKER_COUNT=$(grep -i worker vms.csv | wc -l)
                            
                            echo "Configuration Summary:"
                            echo "- Total VMs: $VM_COUNT"
                            echo "- Masters: $MASTER_COUNT"
                            echo "- Workers: $WORKER_COUNT"
                            echo "- HA Mode: $([ $MASTER_COUNT -gt 1 ] && echo "Yes" || echo "No")"
                        '''
                    }
                }
            }
        }
        
        stage('Prepare Fresh State') {
            steps {
                dir("${TERRAFORM_DIR}") {
                    script {
                        sh '''
                            echo "=========================================="
                            echo "Preparing for new VM deployment..."
                            echo "=========================================="
                            
                            # Move existing state to backup (keep old VMs running)
                            if [ -f "terraform.tfstate" ]; then
                                TIMESTAMP=$(date +%Y%m%d_%H%M%S)
                                mkdir -p state_backups
                                cp terraform.tfstate "state_backups/terraform.tfstate.${TIMESTAMP}"
                                echo "Backed up existing state to state_backups/"
                                
                                # Clear current state to force new resource creation
                                rm -f terraform.tfstate terraform.tfstate.backup
                                echo "Cleared current state for fresh deployment"
                            fi
                            
                            # Clean up Ansible inventory for new deployment
                            rm -rf ../ansible/inventory/*
                            echo "Ready to create NEW VMs (existing VMs will remain untouched)!"
                        '''
                    }
                }
            }
        }
        
        stage('Terraform Init') {
            steps {
                dir("${TERRAFORM_DIR}") {
                    withCredentials([
                        string(credentialsId: 'proxmox-api-url', variable: 'TF_VAR_pm_api_url'),
                        string(credentialsId: 'proxmox-api-token-id', variable: 'TF_VAR_pm_api_token_id'),
                        string(credentialsId: 'proxmox-api-token-secret', variable: 'TF_VAR_pm_api_token_secret')
                    ]) {
                        sh '''
                            echo "Cleaning up old Terraform state..."
                            rm -f .terraform.lock.hcl
                            rm -rf .terraform/
                            
                            echo "Initializing Terraform with fresh state..."
                            terraform init
                        '''
                    }
                }
            }
        }
        
        stage('Terraform Plan') {
            steps {
                dir("${TERRAFORM_DIR}") {
                    withCredentials([
                        string(credentialsId: 'proxmox-api-url', variable: 'TF_VAR_pm_api_url'),
                        string(credentialsId: 'proxmox-api-token-id', variable: 'TF_VAR_pm_api_token_id'),
                        string(credentialsId: 'proxmox-api-token-secret', variable: 'TF_VAR_pm_api_token_secret')
                    ]) {
                        sh '''
                            echo "Planning Terraform deployment..."
                            terraform plan -out=tfplan
                        '''
                    }
                }
            }
        }
        
        stage('Terraform Apply') {
            steps {
                dir("${TERRAFORM_DIR}") {
                    withCredentials([
                        string(credentialsId: 'proxmox-api-url', variable: 'TF_VAR_pm_api_url'),
                        string(credentialsId: 'proxmox-api-token-id', variable: 'TF_VAR_pm_api_token_id'),
                        string(credentialsId: 'proxmox-api-token-secret', variable: 'TF_VAR_pm_api_token_secret')
                    ]) {
                        sh '''
                            echo "Applying Terraform plan..."
                            terraform apply tfplan
                            
                            echo "Infrastructure deployed successfully!"
                            terraform state list
                            
                            echo ""
                            echo "Updated CSV with sequential IP assignments:"
                            cat vms.csv
                        '''
                    }
                }
            }
        }
        
        stage('Prepare Ansible') {
            when {
                expression { params.run_ansible }
            }
            parallel {
                stage('Generate Dynamic Inventory') {
                    steps {
                        dir("${ANSIBLE_DIR}") {
                            sh '''
                                echo "Generating dynamic inventory from CSV..."
                                
                                # Ensure inventory directory exists
                                mkdir -p inventory
                                
                                # Generate inventory from terraform output (dynamic)
                                cd ../terraform
                                # Terraform output returns escaped JSON string, need to decode it
                                terraform output -raw ansible_inventory_json > ../ansible/${INVENTORY_FILE}
                                cd ../ansible
                                
                                echo "Verifying generated inventory JSON:"
                                python3 -m json.tool ${INVENTORY_FILE}
                                
                                echo "Generated inventory:"
                                python3 -m json.tool ${INVENTORY_FILE}
                                
                                echo "Cluster configuration detected:"
                                python3 scripts/show_cluster_config.py ${INVENTORY_FILE}
                                
                                echo ""
                                echo "OS Distribution Analysis:"
                                python3 scripts/detect_os_type.py ${INVENTORY_FILE}
                            '''
                        }
                    }
                }
                stage('Smart VM Readiness Check') {
                    steps {
                        sh '''
                            echo "Smart VM Readiness Check (replaces slow netcat checking)"
                            echo "This should complete in ~15-30 seconds instead of 2+ minutes"
                            
                            cd ${ANSIBLE_DIR}
                            
                            # Give VMs a moment to finish booting
                            echo "Wait for VM initialization (60s)..."
                            sleep 60
                            
                            # Use our smart readiness checker
                            echo "Running smart parallel readiness check..."
                            python3 scripts/smart_vm_ready.py ${INVENTORY_FILE} 3
                            
                            if [ $? -eq 0 ]; then
                                echo "All VMs ready! Proceeding to connectivity test..."
                            else
                                echo "VM readiness check failed. Check logs above."
                                exit 1
                            fi
                        '''
                    }
                }
            }
        }
        
        stage('Final Connectivity Verification') {
            when {
                expression { params.run_ansible }
            }
            steps {
                dir("${ANSIBLE_DIR}") {
                    script {
                        sh '''
                            echo "Final connectivity verification and cluster analysis..."
                            
                            # Quick comprehensive check (replaces multiple slow steps)
                            echo "Running comprehensive cluster check..."
                            export ANSIBLE_INVENTORY_FILE=${INVENTORY_FILE}
                            python3 scripts/quick_cluster_check.py ${INVENTORY_FILE}
                            
                            if [ $? -eq 0 ]; then
                                echo "All connectivity checks passed!"
                                echo "Ready for Kubernetes deployment..."
                            else
                                echo "Connectivity issues detected. Falling back to debug mode..."
                                
                                # Only run detailed debug if quick check fails
                                echo "Debug: Inventory validation"
                                python3 -m json.tool ${INVENTORY_FILE} || echo "JSON validation failed!"
                                
                                echo "Debug: Manual ansible ping test"
                                export ANSIBLE_INVENTORY_FILE=${INVENTORY_FILE}
                                ansible all -i ${INVENTORY_SCRIPT} -m ping --timeout=20 -v || true
                                
                                exit 1
                            fi
                        '''
                    }
                }
            }
        }
        
        stage('Deploy Kubernetes Cluster') {
            when {
                expression { params.run_ansible }
            }
            steps {
                dir("${ANSIBLE_DIR}") {
                    script {
                        sh '''
                            echo "Starting Kubernetes cluster deployment..."
                            
                            echo "Deploying Kubernetes cluster..."
                            ./run-k8s-setup.sh
                            
                            if [ $? -eq 0 ]; then
                                echo "Kubernetes deployment completed successfully!"
                                
                                echo "Cluster endpoints:"
                                python3 scripts/show_endpoints.py ${INVENTORY_FILE}
                            else
                                echo "Kubernetes deployment failed!"
                                exit 1
                            fi
                        '''
                    }
                }
            }
        }
        
        stage('Verify Kubernetes Cluster') {
            when {
                allOf {
                    expression { params.run_ansible }
                    expression { !params.skip_verification }
                }
            }
            steps {
                dir("${ANSIBLE_DIR}") {
                    sh '''
                        echo "Verifying Kubernetes deployment..."
                        
                        # Get first master node
                        FIRST_MASTER=$(python3 scripts/get_first_master.py ${INVENTORY_FILE})
                        
                        if [ -n "$FIRST_MASTER" ]; then
                            echo "Testing kubectl on $FIRST_MASTER..."
                            export ANSIBLE_INVENTORY_FILE=${INVENTORY_FILE}
                            ansible $FIRST_MASTER -i ${INVENTORY_SCRIPT} -m shell -a "kubectl get nodes" --timeout=30
                            ansible $FIRST_MASTER -i ${INVENTORY_SCRIPT} -m shell -a "kubectl get pods --all-namespaces" --timeout=30
                        else
                            echo "No master nodes found in inventory"
                            exit 1
                        fi
                    '''
                }
            }
        }
        
        stage('Extract KUBECONFIG') {
            when {
                expression { params.run_ansible }
            }
            steps {
                dir("${ANSIBLE_DIR}") {
                    script {
                        sh '''
                            echo "Extracting KUBECONFIG from master node..."
                            
                            # Create kubeconfig directory for archiving
                            mkdir -p kubeconfig
                            
                            # Get KUBECONFIG and save to file
                            python3 scripts/get_kubeconfig.py ${INVENTORY_FILE} kubeconfig/admin.conf
                            
                            if [ $? -eq 0 ]; then
                                echo ""
                                echo "==================== KUBECONFIG ===================="
                                echo "KUBECONFIG has been extracted and saved to kubeconfig/admin.conf"
                                echo ""
                                echo "Quick setup commands:"
                                echo "  mkdir -p ~/.kube"
                                echo "  cp admin.conf ~/.kube/config"
                                echo "  chmod 600 ~/.kube/config"
                                echo "  kubectl get nodes"
                                echo ""
                                echo "==================== FULL KUBECONFIG CONTENT ===================="
                                cat kubeconfig/admin.conf
                                echo ""
                                echo "================================================================="
                            else
                                echo "Failed to extract KUBECONFIG"
                                exit 1
                            fi
                        '''
                        
                        // Send to Slack using Jenkins credentials
                        withCredentials([string(credentialsId: 'slack-webhook-url', variable: 'SLACK_WEBHOOK_URL')]) {
                            def kubeconfigContent = readFile("kubeconfig/admin.conf")
                            
                            // Use shell commands to extract cluster info from inventory JSON
                            def masterCount = sh(
                                script: "python3 -c \"import json; data=json.load(open('${INVENTORY_FILE}')); print(len(data.get('k8s_masters', {}).get('hosts', {})))\"",
                                returnStdout: true
                            ).trim() as Integer
                            
                            def workerCount = sh(
                                script: "python3 -c \"import json; data=json.load(open('${INVENTORY_FILE}')); print(len(data.get('k8s_workers', {}).get('hosts', {})))\"",
                                returnStdout: true
                            ).trim() as Integer
                            
                            def clusterMode = masterCount > 1 ? "HA Multi-Master" : "Single Master"
                            
                            // Extract cluster endpoint from kubeconfig
                            def clusterEndpoint = sh(
                                script: "grep 'server:' kubeconfig/admin.conf | awk '{print \$2}'",
                                returnStdout: true
                            ).trim() ?: "N/A"
                            
                            // Base64 encode kubeconfig
                            def kubeconfigB64 = kubeconfigContent.bytes.encodeBase64().toString()
                            
                            // Create Slack message using shell
                            def timestamp = sh(
                                script: "date -u '+%Y-%m-%d %H:%M:%S UTC'",
                                returnStdout: true
                            ).trim()
                            
                            // Create a simple Slack message
                            sh """
                                cat > slack_message.json << 'EOF'
{
    "blocks": [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": "üöÄ Kubernetes Cluster Deployed Successfully"
            }
        },
        {
            "type": "section",
            "fields": [
                {
                    "type": "mrkdwn",
                    "text": "*Deployment Time:*\\n${timestamp}"
                },
                {
                    "type": "mrkdwn",
                    "text": "*Cluster Endpoint:*\\n\`${clusterEndpoint}\`"
                },
                {
                    "type": "mrkdwn",
                    "text": "*Cluster Mode:*\\n${clusterMode}"
                },
                {
                    "type": "mrkdwn",
                    "text": "*Total Nodes:*\\n${masterCount} masters, ${workerCount} workers"
                }
            ]
        },
        {
            "type": "divider"
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*üìã Quick Setup Instructions:*\\n\`\`\`bash\\n# Save the kubeconfig to ~/.kube/config\\nmkdir -p ~/.kube\\ncp admin.conf ~/.kube/config\\nchmod 600 ~/.kube/config\\n\\n# Test connection\\nkubectl get nodes\\n\`\`\`"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*üîê KUBECONFIG Preview:*\\n\`\`\`yaml\\n${kubeconfigContent.take(300).replaceAll('"', '\\\\"').replaceAll('\n', '\\\\n')}...\\n\`\`\`\\n_Full content available in Jenkins build artifacts_"
            }
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": "‚ö†Ô∏è *Security Notice:* This KUBECONFIG provides full cluster admin access. Store it securely."
                }
            ]
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*Jenkins Build:* <${BUILD_URL}|View Build #${BUILD_NUMBER}>"
            }
        }
    ]
}
EOF
                                
                                # Send to Slack using curl
                                echo "Sending notification to Slack..."
                                curl -X POST ${SLACK_WEBHOOK_URL} \\
                                     -H "Content-Type: application/json" \\
                                     -d @slack_message.json \\
                                     --silent --show-error --fail \\
                                && echo "‚úÖ KUBECONFIG sent to Slack successfully!" \\
                                || echo "‚ùå Failed to send to Slack"
                                
                                # Clean up
                                rm -f slack_message.json
                            """
                        }
                    }
                }
            }
        }
        
        stage('Show Summary') {
            steps {
                dir("${TERRAFORM_DIR}") {
                    withCredentials([
                        string(credentialsId: 'proxmox-api-url', variable: 'TF_VAR_pm_api_url'),
                        string(credentialsId: 'proxmox-api-token-id', variable: 'TF_VAR_pm_api_token_id'),
                        string(credentialsId: 'proxmox-api-token-secret', variable: 'TF_VAR_pm_api_token_secret')
                    ]) {
                        sh '''
                            echo "==================== DEPLOYMENT SUMMARY ===================="
                            terraform output assignment_summary
                            
                            echo ""
                            echo "==================== INFRASTRUCTURE DETAILS ===================="
                            terraform output vm_assignments
                        '''
                    }
                }
            }
        }
    }
    
    post {
        always {
            script {
                if (params.run_ansible) {
                    archiveArtifacts artifacts: "${ANSIBLE_DIR}/inventory/*", allowEmptyArchive: true
                    archiveArtifacts artifacts: "${TERRAFORM_DIR}/vms.csv", allowEmptyArchive: true
                    
                    archiveArtifacts artifacts: "${ANSIBLE_DIR}/kubeconfig/*", allowEmptyArchive: true
                }
            }
        }
        
        success {
            script {
                def successMessage = """
            ==================== SUCCESS ====================
            Infrastructure deployment completed successfully!
            
            Deployment Type: NEW VMs (Previous VMs remain untouched)
            
            What was deployed:
            - Brand NEW VMs provisioned with Terraform
            - Previous VMs still running (not destroyed)
            - Kubernetes cluster configured on new VMs
            - Dynamic inventory generated automatically"""
            
                successMessage += """
            - KUBECONFIG extracted and archived
            
            Kubernetes Access:
            - Download 'kubeconfig/admin.conf' from Jenkins artifacts
            - Run: mkdir -p ~/.kube && cp admin.conf ~/.kube/config
            - Test: kubectl get nodes"""
                
                successMessage += """
            
            Next steps:
            - Access services using endpoints shown above
            - Check archived files for configuration details
            - Scale or modify as needed
            
            Cleanup (if needed):
            - cd terraform && terraform destroy --auto-approve
            ==================================================
            """
            
                echo successMessage
            }
        }
        
        failure {
            echo """
            ==================== FAILURE ====================
            Pipeline execution failed!
            
            Common troubleshooting steps:
            1. Check Terraform state and resources
            2. Verify VM connectivity and SSH access
            3. Validate Ansible inventory and playbooks
            4. Check network connectivity to target VMs
            5. Review stage logs for specific errors
            ==================================================
            """
        }
        
        cleanup {
            sh '''
                echo "Cleaning up temporary files..."
                rm -f ${TERRAFORM_DIR}/tfplan
                # Note: keeping inventory for artifact archiving
            '''
        }
    }
}